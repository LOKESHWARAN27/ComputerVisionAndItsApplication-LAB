{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h1fqm_iTVU_Z",
        "outputId": "b1bd132a-7fa5-4e9a-ab76-76ee0047da10"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to initialize the list of trackers (for older versions of OpenCV)\n",
        "def initialize_trackers():\n",
        "    trackers = []  # List to hold trackers for each object\n",
        "    return trackers\n",
        "\n",
        "# Function to add individual trackers for each object\n",
        "def add_tracker(trackers, frame, bbox):\n",
        "    tracker = cv2.TrackerKCF_create()  # Create a KCF tracker (you can choose others like MIL, TLD, etc.)\n",
        "    tracker.init(frame, bbox)\n",
        "    trackers.append(tracker)\n",
        "\n",
        "# Function to update trackers and get the new bounding boxes\n",
        "def update_trackers(trackers, frame):\n",
        "    success = []\n",
        "    boxes = []\n",
        "    for tracker in trackers:\n",
        "        ok, bbox = tracker.update(frame)\n",
        "        success.append(ok)\n",
        "        boxes.append(bbox)\n",
        "    return success, boxes\n",
        "\n",
        "# Function to detect objects (using background subtraction)\n",
        "def detect_objects(frame, fgbg):\n",
        "    fgmask = fgbg.apply(frame)\n",
        "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    bboxes = []\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        if w > 50 and h > 50:  # Filter out small objects\n",
        "            bboxes.append((x, y, w, h))\n",
        "    return bboxes\n",
        "\n",
        "# Function to display images in Jupyter\n",
        "def display_frame(frame):\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(frame_rgb)\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()\n",
        "\n",
        "# Main function to track objects in the video\n",
        "def track_objects(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fgbg = cv2.createBackgroundSubtractorMOG2()  # Background subtractor\n",
        "\n",
        "    trackers = initialize_trackers()  # List to hold individual trackers\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Detect objects in the current frame\n",
        "        bboxes = detect_objects(frame, fgbg)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Add new trackers for each detected object\n",
        "        for bbox in bboxes:\n",
        "            add_tracker(trackers, frame, bbox)\n",
        "\n",
        "        # Update trackers and get bounding boxes\n",
        "        success, boxes = update_trackers(trackers, frame)\n",
        "\n",
        "        # Draw bounding boxes for tracked objects\n",
        "        for i, new_box in enumerate(boxes):\n",
        "            x, y, w, h = [int(v) for v in new_box]\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"Object {i+1}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        # Display the resulting frame in the notebook\n",
        "        display_frame(frame)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "# Call the tracking function with the video path\n",
        "video_path ='/content/stock-footage-autonomous-car-driving-through-los-angeles-computer-vision-object-detection-system-that-creates.webm'  # Replace with the path to your video file\n",
        "track_objects(video_path)\n"
      ]
    }
  ]
}